{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Genre of Books from Summaries\n",
    "\n",
    "We'll use a set of book summaries from the [CMU Book Summaries Corpus](http://www.cs.cmu.edu/~dbamman/booksummaries.html) in this experiment.  This contains a large number of summaries (16,559) and includes meta-data about the genre of the books taken from Freebase.  Each book can have more than one genre and there are 227 genres listed in total.  To simplify the problem of genre prediction we will select a small number of target genres that occur frequently in the collection and select the books with these genre labels.  This will give us one genre label per book. \n",
    "\n",
    "Your goal in this portfolio is to take this data and build a predictive model to classify the books into one of the five target genres.  You will need to extract suitable features from the texts and select a suitable model to classify them. You should build at least one model but you could build two and compare the results if you have time.\n",
    "\n",
    "You should report on each stage of your experiment as you work with the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The first task is to read the data. It is made available in tab-separated format but has no column headings. We can use `read_csv` to read this but we need to set the separator to `\\t` (tab) and supply the column names.  The names come from the [ReadMe](data/booksummaries/README.txt) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>fid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1756</td>\n",
       "      <td>/m/0sww</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td>David Hume</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The argument of the Enquiry proceeds by a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>/m/0wkt</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>{\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wid      fid                                      title           author  \\\n",
       "0   620  /m/0hhy                                Animal Farm    George Orwell   \n",
       "1   843  /m/0k36                         A Clockwork Orange  Anthony Burgess   \n",
       "2   986  /m/0ldx                                 The Plague     Albert Camus   \n",
       "3  1756  /m/0sww  An Enquiry Concerning Human Understanding       David Hume   \n",
       "4  2080  /m/0wkt                       A Fire Upon the Deep     Vernor Vinge   \n",
       "\n",
       "         date                                             genres  \\\n",
       "0  1945-08-17  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "1        1962  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
       "2        1947  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
       "3                                                                  \n",
       "4              {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
       "\n",
       "                                             summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The argument of the Enquiry proceeds by a ser...  \n",
       "4   The novel posits that space around the Milky ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['wid', 'fid', 'title', 'author', 'date', 'genres', 'summary']\n",
    "\n",
    "books = pd.read_csv(\"data/booksummaries/booksummaries.txt\", sep=\"\\t\", header=None, names=names, keep_default_na=False)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next filter the data so that only our target genre labels are included and we assign each text to just one of the genre labels.  It's possible that one text could be labelled with two of these labels (eg. Science Fiction and Fantasy) but we will just assign one of those here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8954, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_genres = [\"Children's literature\",\n",
    "                 'Science Fiction',\n",
    "                 'Novel',\n",
    "                 'Fantasy',\n",
    "                 'Mystery']\n",
    "\n",
    "# create a Series of empty strings the same length as the list of books\n",
    "genre = pd.Series(np.repeat(\"\", books.shape[0]))\n",
    "# look for each target genre and set the corresponding entries in the genre series to the genre label\n",
    "for g in target_genres:\n",
    "    genre[books['genres'].str.contains(g)] = g\n",
    "\n",
    "# add this to the book dataframe and then select only those rows that have a genre label\n",
    "# drop some useless columns\n",
    "books['genre'] = genre\n",
    "genre_books = books[genre!=''].drop(['genres', 'fid', 'wid'], axis=1)\n",
    "\n",
    "genre_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Children's literature</th>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novel</th>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  author  date  summary\n",
       "genre                                              \n",
       "Children's literature   1092    1092  1092     1092\n",
       "Fantasy                 2311    2311  2311     2311\n",
       "Mystery                 1396    1396  1396     1396\n",
       "Novel                   2258    2258  2258     2258\n",
       "Science Fiction         1897    1897  1897     1897"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many books we have in each genre category\n",
    "genre_books.groupby('genre').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "We start the process by cleaning up the summary texts. This includes\n",
    "\n",
    "- Conversion to lowercase\n",
    "- Tokenization\n",
    "- Removal of numeric tokens\n",
    "- Removal of punctuation\n",
    "- Removal of stopwords\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download ('stopwords')\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "stopwords = list(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_summaries = []\n",
    "\n",
    "summaries = genre_books.summary\n",
    "\n",
    "# step 1: convert whole text to lowercase\n",
    "summaries = summaries.str.lower().to_list()\n",
    "\n",
    "for summary in summaries:\n",
    "    # step 2: tokenize all the words\n",
    "    tokens = word_tokenize(summary)\n",
    "\n",
    "    # step 3: remove all numeric tokens\n",
    "    re_num = re.compile(r'[0-9]')\n",
    "    tokens = [i for i in tokens if not re_num.match(i)]\n",
    "    \n",
    "    # step 4: remove all punctuation\n",
    "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
    "    tokens = [i for i in tokens if not re_punc.match(i)]\n",
    "    \n",
    "    # step 5: remove all the stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords]\n",
    "    \n",
    "    #step 6: lemmatize all the tokens\n",
    "    tokens = [wnl.lemmatize(word) for word in tokens]\n",
    "\n",
    "    tokenized_summaries.append(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) from Scikit-Learn in order to obtain a matrix of TF-IDF features of the summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2, max_features=70000, strip_accents='unicode',\n",
    "                            analyzer='word', token_pattern=r'\\w+', use_idf=True, \n",
    "                            smooth_idf=True, sublinear_tf=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(tokenized_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to divide the dataset into training and test sets. We will take 20% of the total dataset as the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: x: (7163, 38553) y: (7163,)\n",
      "Testing: x: (1791, 38553) y: (1791,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_matrix, genre_books['genre'], test_size=0.2)\n",
    "\n",
    "print('Training: x:', x_train.shape, 'y:', y_train.shape)\n",
    "print('Testing: x:', x_test.shape, 'y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to build a model. We are going to take a look at two methods: logistic regression and multinomial naive bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We are going to use `linear_model` from Scikit-Learn to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=450, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg_classifier = linear_model.LogisticRegression(solver= 'sag', max_iter=200, random_state=450)\n",
    "reg_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.6929177780161613\n",
      "Accuracy: 0.711892797319933\n"
     ]
    }
   ],
   "source": [
    "predictions = reg_classifier.predict(x_test)\n",
    "print('F1 score:', metrics.f1_score(y_test, predictions, average='macro'))\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see how this model performs on the first 5 books from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal Farm \n",
      "Predicted: Children's literature \n",
      "Actual: Children's literature \n",
      "\n",
      "A Clockwork Orange \n",
      "Predicted: Novel \n",
      "Actual: Novel \n",
      "\n",
      "The Plague \n",
      "Predicted: Novel \n",
      "Actual: Novel \n",
      "\n",
      "A Fire Upon the Deep \n",
      "Predicted: Fantasy \n",
      "Actual: Fantasy \n",
      "\n",
      "A Wizard of Earthsea \n",
      "Predicted: Science Fiction \n",
      "Actual: Fantasy \n",
      "\n",
      "Got 4 out of 5 correct.\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "while total < 5:\n",
    "    try:\n",
    "        prediction = reg_classifier.predict(vectorizer.transform(tokenized_summaries)[idx])[0]\n",
    "        actual = genre_books['genre'][idx]\n",
    "        if (prediction == actual):\n",
    "            correct += 1\n",
    "        print(genre_books['title'][idx], '\\nPredicted:', prediction, '\\nActual:', actual, '\\n')\n",
    "        total += 1\n",
    "    except:\n",
    "        continue\n",
    "    finally:\n",
    "        idx += 1\n",
    "\n",
    "print('Got', correct, 'out of', total, 'correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes\n",
    "\n",
    "For this method, we will use `naive_bayes.MultinomialNB` from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.45, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_classifier = MultinomialNB(alpha=.45)\n",
    "mnb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5636639050191085\n",
      "Accuracy: 0.644891122278057\n"
     ]
    }
   ],
   "source": [
    "predictions = mnb_classifier.predict(x_test)\n",
    "print('F1 score:', metrics.f1_score(y_test, predictions, average='macro'))\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both F1 score and accuracy are lower for naive bayes classifier than those for logistic regression. This can also be observed when we test the model on the first 5 books from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal Farm \n",
      "Predicted: Novel \n",
      "Actual: Children's literature \n",
      "\n",
      "A Clockwork Orange \n",
      "Predicted: Novel \n",
      "Actual: Novel \n",
      "\n",
      "The Plague \n",
      "Predicted: Novel \n",
      "Actual: Novel \n",
      "\n",
      "A Fire Upon the Deep \n",
      "Predicted: Fantasy \n",
      "Actual: Fantasy \n",
      "\n",
      "A Wizard of Earthsea \n",
      "Predicted: Science Fiction \n",
      "Actual: Fantasy \n",
      "\n",
      "Got 3 out of 5 correct.\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "while total < 5:\n",
    "    try:\n",
    "        prediction = mnb_classifier.predict(vectorizer.transform(tokenized_summaries)[idx])[0]\n",
    "        actual = genre_books['genre'][idx]\n",
    "        if (prediction == actual):\n",
    "            correct += 1\n",
    "        print(genre_books['title'][idx], '\\nPredicted:', prediction, '\\nActual:', actual, '\\n')\n",
    "        total += 1\n",
    "    except:\n",
    "        continue\n",
    "    finally:\n",
    "        idx += 1\n",
    "\n",
    "print('Got', correct, 'out of', total, 'correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "\n",
    "Finally, we will save both the models in the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books-genre-naive-bayes.gz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(reg_classifier, 'books-genre-linear-regression.gz')\n",
    "dump(mnb_classifier, 'books-genre-naive-bayes.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can later be loaded by `joblib.load` function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
